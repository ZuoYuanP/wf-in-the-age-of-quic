#!/usr/bin/env python3
"""
Usage: compute-tree-importance [options] INFILE FEATURES SPLITS [OUTFILE]

INFILE is an HDF containing the labels key.  FEATURES is a npy file
with features for k-FP, SPLITS is a json file with splitting indices,
results are written to outfile in CSV format.

Options:
    --pred-output filename
        Write the predictions to filename.

    --seed val
        Seed the random number generator with val [default: 7074].
"""
import time
import json
import pathlib
import logging
from typing import NamedTuple, Iterator

import h5py
import doceasy
import numpy as np
import sklearn
import sklearn.inspection
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

from lab.classifiers import kfingerprinting

_LOGGER = logging.getLogger("compute-feature-importance")


def _unpack_splits(splits):
    for split in splits:
        yield split["train-val"], split["test"]


def main(
    infile: str, features: str, splits: str, outfile, pred_output, seed
):
    """Script entrypoint."""
    logging.basicConfig(
        format='[%(asctime)s] [%(levelname)s] %(name)s - %(message)s',
        level=logging.INFO)
    start = time.perf_counter()

    with h5py.File(infile, mode="r") as h5file:
        y = np.asarray(h5file["labels"]["class"])
    features = np.load(features)
    split_idx = [
        json.loads(line) for line in pathlib.Path(splits).read_text().split()]

    random_state = np.random.RandomState(seed)

    # Write the header
    pred_output.writerow(
        ["run", "classifier", "y_true"] + [str(c) for c in range(-1, 100)]
    )

    for i, result in enumerate(_measure_feature_importance(
        features, y, split_idx, random_state=random_state
    )):
        outfile.writerow(result.importances)

        n_samples = len(result.y_true)
        predictions = np.hstack((
            # Column for the current split index
            np.full((2 * n_samples, 1), i),
            # Zeroes for kfp predictions, ones for RF predictions
            np.vstack((np.zeros((n_samples, 1)), np.ones((n_samples, 1)))),
            # The true values for the predictions
            np.concatenate((result.y_true, result.y_true)).reshape((-1, 1)),
            # The k-FP probabilities and random forest probabilities
            np.vstack((result.kfp_proba, result.rf_proba))
        ))
        pred_output.writerows(predictions)

    _LOGGER.info("Script complete in %.2fs.", (time.perf_counter() - start))


FeatureImportanceResult = NamedTuple("FeatureImportanceResult", [
    ("importances", np.ndarray), ("kfp_proba", np.ndarray),
    ("rf_proba", np.ndarray), ("y_true", np.ndarray)
])


def _measure_feature_importance(
    X, y, splits, random_state=None
) -> Iterator[FeatureImportanceResult]:
    for i, (train_idx, test_idx) in enumerate(_unpack_splits(splits)):
        _LOGGER.info("Evaluating split %d/%d...", (i+1), len(splits))

        # Keep the classifier out of the pipeline as we want to predict on k-FP
        # and its underlying classifier
        feature_pipeline = sklearn.pipeline.Pipeline([
            ("impute", SimpleImputer(missing_values=np.nan, strategy="mean")),
            ("standardize", StandardScaler()),
        ])
        kfp = kfingerprinting.KFingerprintingClassifier(
            n_neighbours=6, unknown_label=-1, random_state=random_state,
            n_jobs=-1)

        _LOGGER.info("Fitting the classifier...")
        kfp.fit(
            feature_pipeline.fit_transform(X[train_idx]),
            y[train_idx]
        )
        forest = kfp.forest_

        x_test = feature_pipeline.transform(X[test_idx])

        _LOGGER.info("Predicting for kfp...")
        kfp_proba = kfp.predict_proba(x_test)
        _LOGGER.info("Predicting for the random forest...")
        rf_proba = forest.predict_proba(x_test)

        yield FeatureImportanceResult(
            forest.feature_importances_, kfp_proba, rf_proba, y[test_idx]
        )


if __name__ == "__main__":
    main(**doceasy.doceasy(__doc__, {
        "INFILE": str,
        "FEATURES": str,
        "SPLITS": str,
        "OUTFILE": doceasy.CsvFile(mode="w", default="-"),
        "--seed": doceasy.Use(int),
        "--pred-output": doceasy.CsvFile(mode="w"),
    }))
